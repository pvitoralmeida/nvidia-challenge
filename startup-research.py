
import os
import pandas as pd
from crewai import Agent, Task, Crew, Process, LLM
from crewai_tools import ScrapeWebsiteTool

# --- 1. Configura√ß√£o Inicial --- #

# Carrega a chave da API do ambiente
PERPLEXITY_API_KEY = os.environ.get("PERPLEXITY_API_KEY")

if not PERPLEXITY_API_KEY:
    raise ValueError("A vari√°vel de ambiente PERPLEXITY_API_KEY n√£o est√° definida.")

# Instancia o LLM para todos os agentes
perplexity_llm = LLM(
    model="sonar",
    base_url="https://api.perplexity.ai/",
    api_key=PERPLEXITY_API_KEY
)

# Instancia a ferramenta de scraping
scrape_tool = ScrapeWebsiteTool()

# --- 2. Defini√ß√£o de Agentes --- #

vc_research_agent = Agent(
    role="Especialista em Venture Capital e Intelig√™ncia de Mercado",
    goal="Coletar e organizar informa√ß√µes detalhadas sobre startups de tecnologia na Am√©rica Latina que receberam investimentos de firmas espec√≠ficas de Venture Capital",
    backstory=(
        """Voc√™ √© um analista s√™nior de venture capital com amplo conhecimento
        do ecossistema de startups latino-americanas e experi√™ncia em monitorar
        portf√≥lios de fundos de investimento. Voc√™ tem conhecimento atualizado sobre
        o mercado de VC na regi√£o e pode identificar startups relevantes investidas
        por essas firmas baseado em seu conhecimento e pesquisa online.
        
        IMPORTANTE: Sua meta √© identificar NO M√çNIMO 25 startups √∫nicas para garantir
        que o pipeline final tenha pelo menos 50 startups ap√≥s o enriquecimento.
        
        Sua miss√£o √© identificar startups de tecnologia investidas por VCs listadas,
        trazendo dados confi√°veis, claros e estruturados em formato CSV.
        Voc√™ nunca inventa informa√ß√µes: apenas utiliza dados concretos que conhece
        ou pode verificar. Suas an√°lises s√£o objetivas e segue estritamente o output esperado."""
    ),
    llm=perplexity_llm,
    verbose=True
)

portfolio_analyser_agent = Agent(
    role="Especialista em An√°lise de Portf√≥lio e Riqueza de Dados",
    goal="Completar as informa√ß√µes coletadas pelo primeiro agente usando scraping, buscando o m√°ximo de startups poss√≠vel",
    backstory=("""
        Voc√™ √© um analista de dados especializado em venture capital e startups.
        Seu foco √© examinar cuidadosamente os portf√≥lios oficiais das firmas de VC
        usando ferramentas de web scraping para identificar startups investidas,
        detalhes de rodadas, setores e datas relevantes. 
        
        META CR√çTICA: Voc√™ deve garantir que o resultado final tenha PELO MENOS 50 startups √∫nicas.
        Se ap√≥s o scraping inicial n√£o atingir essa meta, voc√™ deve:
        1. Expandir a pesquisa para mais VCs da lista
        2. Incluir startups de diferentes est√°gios (pre-seed, seed, growth)
        
        Sua miss√£o √© complementar e validar as informa√ß√µes coletadas pelo primeiro agente, 
        garantindo precis√£o, consist√™ncia e clareza atrav√©s de scraping real das p√°ginas web.
        
        INSTRU√á√ïES ESPEC√çFICAS PARA USO DE FERRAMENTAS:
        1. Use ScrapeWebsiteTool para acessar cada URL de portf√≥lio fornecida
        2. Extraia informa√ß√µes reais das p√°ginas web dos portf√≥lios
        3. Procure por se√ß√µes como "Portfolio", "Companies", "Investments", "Our Companies"
        4. Para cada startup encontrada, colete:
           - Nome da empresa
           - Pa√≠s Sede
           - Site oficial (quando dispon√≠vel)
           - Setor/√°rea de atua√ß√£o
           - Detalhes do investimento (quando dispon√≠vel)
           - Informa√ß√µes dos fundadores
        5. Se n√£o atingir 50 startups, expanda para incluir:
           - Diferentes est√°gios de investimento
           - Mais VCs da lista fornecida
        6. Se n√£o encontrar informa√ß√µes espec√≠ficas, indique como "N/A" ou deixe em branco
        
        Voc√™ nunca inventa informa√ß√µes: apenas utiliza dados concretos extra√≠dos das p√°ginas.
        """),
    llm=perplexity_llm,
    tools=[scrape_tool],
    verbose=True
)

startup_analyser_agent = Agent(
    role="Especialista em An√°lise de Startups e Riqueza de Dados",
    goal="Enriquecer as informa√ß√µes das startups com dados detalhados de mercado, financeiros e operacionais",
    backstory=("""
        Voc√™ √© um especialista rigoroso em valida√ß√£o de dados. Sua fun√ß√£o √© verificar se o dataset final cont√©m startups √∫nicas e v√°lidas, 
        removendo duplicatas e entradas inv√°lidas.
        
        METODOLOGIA (6 ETAPAS):
        1. Valida√ß√£o inicial dados b√°sicos
        2. Scraping inteligente site oficial  
        3. Pesquisa complementar LinkedIn/Crunchbase/Github
        4. Cross-validation entre fontes
        5. Enrichment com contexto de mercado
        6. Quality check consist√™ncia/completude
        
        FONTES PRIORIT√ÅRIAS: Website oficial, LinkedIn fundadores, Crunchbase/AngelList/Github,
        press releases, relat√≥rios setoriais, plataformas review
        
        DADOS SEMPRE ENRIQUECIDOS: github, TAM/SAM, tech stack, tamanho equipe.
        
        PRINC√çPIO FUNDAMENTAL: NUNCA inventa informa√ß√µes. Dados n√£o encontrados = "N/A".
        Trabalha sistematicamente, documenta fontes, mant√©m alto padr√£o qualidade.
        Objetivo: transformar lista b√°sica em database acion√°vel para decis√µes investimento."""
    ),
    llm=perplexity_llm,
    verbose=True,
    max_iter=3,
    memory=True 
)

revisor_agent = Agent(
    role="Validador de Qualidade de Dados",
    goal="Garantir que o resultado final contenha startups √∫nicas e v√°lidas",
    backstory=("""
        Voc√™ √© um especialista rigoroso em valida√ß√£o de dados e controle de qualidade.
        Sua √∫nica fun√ß√£o √© verificar se o dataset final est√° adequado.
        
        REGRAS OBRIGAT√ìRIAS:
        1. Contar o n√∫mero total de startups no dataset
        2. Verificar e remover duplicatas (mesmo nome de startup)
        3. Remover entradas inv√°lidas ou vazias
        
        Voc√™ √© inflex√≠vel quanto ao output e n√£o aceita NADA que n√£o seja um CSV puro com as startups.
        """
    ),
    llm=perplexity_llm,
    verbose=True
)

format_guardian_agent = Agent(
    role="Especialista em Padroniza√ß√£o de Sa√≠da",
    goal="Garantir que as respostas estejam estritamente no formato CSV solicitado",
    backstory=("""
        Voc√™ √© um especialista em valida√ß√£o de dados e padroniza√ß√£o de sa√≠das.
        Seu foco √© revisar, ajustar e garantir que qualquer resultado gerado esteja
        exatamente no formato solicitado: uma tabela CSV PURA, sem coment√°rios extras,
        sem blocos markdown e apenas com as colunas exigidas.
        
        Voc√™ combina dados de m√∫ltiplas fontes, elimina duplicatas, padroniza formatos
        e garante consist√™ncia em todas as informa√ß√µes.
        """),
    llm=perplexity_llm,
    verbose=True
)

# --- 3. Defini√ß√£o de Tarefas --- #

vc_research_task = Task(
    description=("""
        Pesquise startups latinas (menos do Brasil) de tecnologia que receberam investimentos em 2023-2025
        pelas seguintes firmas de Venture Capital: {vc_list}.
        
        Para cada VC listada, identifique PELO MENOS 1-2 startups que receberam
        investimentos nesse per√≠odo. Use seu conhecimento do ecossistema de startups
        latino-americano para identificar:
        
        - Startups de fintech, e-commerce, healthtech, edtech, proptech, logistics
        - Rodadas de investimento Pre-seed, Seed, Series A, Series B, Growth
        - Informa√ß√µes p√∫blicas sobre os investimentos
        
        Priorize startups inovadoras em tecnologia e forne√ßa informa√ß√µes detalhadas
        quando dispon√≠veis. Se n√£o tiver informa√ß√£o espec√≠fica sobre um campo,
        indique como "N/A"."""
    ),
    expected_output="""
    Forne√ßa em formato CSV APENAS a tabela, SEM conclus√µes, introdu√ß√µes ou texto extra.
    N√ÉO INVENTE exemplos fict√≠cios - use apenas informa√ß√µes que voc√™ conhece.
    As colunas DEVEM SER exatamente as seguintes (nessa ordem):
    - Nome da Startup
    - Pa√≠s Sede
    - Site
    - Setor
    - Ano de Funda√ß√£o
    - Valor do Investimento
    - Rodada (Seed, Series A, B, etc.)
    - Data do Investimento
    - Venture Capital Investidor
    - LinkedIn do Fundador""",
    agent=vc_research_agent,
    output_file="startups_pesquisa_inicial.csv"
)

portfolio_analyser_task = Task(
    description=("""
        Fa√ßa scraping dos portf√≥lios oficiais das firmas de Venture Capital: {portfolio_list}
        
        INSTRU√á√ïES OBRIGAT√ìRIAS:
        1. Para CADA URL fornecida, use ScrapeWebsiteTool(website_url="URL_AQUI") para extrair o conte√∫do
        2. Analise o HTML/conte√∫do extra√≠do procurando por:
           - Listas de empresas investidas
           - Se√ß√µes de portf√≥lio
           - Informa√ß√µes de startups de tecnologia
           - Detalhes de investimentos quando dispon√≠veis
        3. Para cada startup encontrada, tente extrair:
           - Nome da empresa
           - Site/URL oficial
           - Setor de atua√ß√£o
           - Ano de funda√ß√£o (se dispon√≠vel)
           - Detalhes do investimento (valor, rodada, data)
           - Informa√ß√µes dos fundadores
        4. Combine com os dados do primeiro agente, mas priorize informa√ß√µes extra√≠das via scraping
        5. Elimine duplicatas e padronize informa√ß√µes
        
        IMPORTANTE: 
        - Use a ferramenta de scraping para cada URL individual
        - N√£o invente informa√ß√µes - apenas use dados extra√≠dos
        """),
    expected_output="Formato CSV com as mesmas colunas da tarefa anterior, complementado com os dados do scraping.",
    agent=portfolio_analyser_agent,
    context=[vc_research_task],
    output_file="startups_enriquecidos_portfolio.csv"
)

startup_analysis_task = Task(
    description="Enrique√ßa os dados de cada startup com informa√ß√µes detalhadas sobre produto, tecnologias, equipe, etc.",
    expected_output="CSV enriquecido com colunas adicionais: Link do Github, Tecnologias Utilizadas, Tamanho da Equipe, Tamanho do Mercado.",
    agent=startup_analyser_agent,
    context=[portfolio_analyser_task], 
    output_file="startups_enriquecidos_startup.csv"
)

review_task = Task(
    description="Valide o dataset coletado, garantindo que todas as startups sejam √∫nicas e v√°lidas, removendo duplicatas e entradas inv√°lidas e garantindo que todas as colunas estejam com valores coerentes.",
    expected_output="Um arquivo CSV contendo todas as startups validadas, sem duplicatas e sem entradas inv√°lidas.",
    agent=revisor_agent,
    context=[startup_analysis_task],
    output_file="startups_revisado.csv"
)

final_csv_task = Task(
    description="Formate a sa√≠da final em um √∫nico arquivo CSV, garantindo que todos os dados estejam consistentes e bem estruturados.",
    expected_output="Um √∫nico arquivo CSV chamado 'startups_final.csv' contendo todas as startups validadas e formatadas.",
    agent=format_guardian_agent,
    context=[review_task],
    output_file="startups_final.csv"
)

# --- 4. Fun√ß√µes de Execu√ß√£o e Mesclagem --- #

def load_and_merge_data(new_data_path, final_data_path):
    """
    Carrega dados existentes, mescla com novos dados e remove duplicatas.
    """
    if not os.path.exists(new_data_path):
        print(f"Aviso: O arquivo {new_data_path} n√£o foi encontrado. Nenhuma nova startup para mesclar.")
        return

    new_df = pd.read_csv(new_data_path)
    
    if os.path.exists(final_data_path):
        existing_df = pd.read_csv(final_data_path)
        combined_df = pd.concat([existing_df, new_df], ignore_index=True)
        combined_df.drop_duplicates(subset=['Nome da Startup', 'Site'], keep='first', inplace=True)
        combined_df.to_csv(final_data_path, index=False)
        print(f"Dados mesclados e deduplicados em {final_data_path}. Total de startups: {len(combined_df)}")
    else:
        new_df.to_csv(final_data_path, index=False)
        print(f"Novo arquivo {final_data_path} criado. Total de startups: {len(new_df)}")

def run_crew_challenge(vc_list, portfolio_list):
    """
    Executa o desafio NVIDIA usando CrewAI para pesquisar e enriquecer dados de startups.
    """
    crew = Crew(
        agents=[
            vc_research_agent,
            portfolio_analyser_agent,
            startup_analyser_agent,
            revisor_agent,
            format_guardian_agent
        ],
        tasks=[
            vc_research_task,
            portfolio_analyser_task,
            startup_analysis_task,
            review_task,
            final_csv_task
        ],
        process=Process.sequential,
        verbose=True
    )

    result = crew.kickoff(inputs={'vc_list': vc_list, 'portfolio_list': portfolio_list})
    
    load_and_merge_data("startups_final.csv", "startups_consolidado.csv")
    
    return result

# --- 5. Listas de VCs e Portf√≥lios --- #

vc_list = [
    "Kaszek Ventures", "Monashees", "Valor Capital Group", "NXTP Ventures", "Canary", "Astella Investimentos", "Ignia Partners",
    "Dalus Capital", "Maya Capital", "Mouro Capital", "Redwood Ventures", "Endeavor Catalyst",
    "Variv Capital", "Seaya Ventures", "Genesis Ventures", "Cometa VC", "Magma Partners"
]

portfolio_list = [
    "https://kaszek.com/companies/",
    "https://www.monashees.com/portfolio",
    "https://www.valorcapitalgroup.com/companies",
    "https://www.nxtp.vc/portfolio",
    "https://canary.com.br/portfolio/",
    "https://www.astella.com.br/pt/portfolio",
    "https://www.ignia.vc/portfolio",
    "https://daluscapital.com/portfolio",
    "https://mayacapital.com/portfolio/",
    "https://www.mourocapital.com/our-portfolio/",
    "https://redwood.ventures/portfolio",
    "https://www.mapeos.endeavor.org.ar/",
    "https://variv.com/",
    "https://seaya.vc/portfolio/",
    "https://genesisventures.vc/genesis-ventures-i/",
    "https://www.cometa.vc/portfolio",
    "https://magmapartners.com/companies"
]

# --- 6. Execu√ß√£o Principal --- #

if __name__ == "__main__":
    print("üéØ NVIDIA Challenge - Pipeline de Coleta e Enriquecimento de Startups")
    print(f"üìä VCs a pesquisar: {len(vc_list)}")
    print(f"üîó Portf√≥lios para scraping: {len(portfolio_list)}")
    print("-" * 60)
    
    try:
        resultado_final = run_crew_challenge(vc_list, portfolio_list)
        
        print("\n" + "=" * 60)
        print("üéâ EXECU√á√ÉO CONCLU√çDA COM SUCESSO!")
        print("=" * 60)
        print(f"üìÑ Resultado final do Crew: {resultado_final}")
        print("\nüìÅ Arquivos gerados:")
        print("   - startups_final.csv (startups coletadas nesta execu√ß√£o)")
        print("   - startups_consolidado.csv (base de dados acumulada e deduplicada)")
        
    except Exception as e:
        print(f"\n‚ùå ERRO durante a execu√ß√£o: {e}")
        print("üîß Verifique se todas as depend√™ncias est√£o instaladas e as chaves de API s√£o v√°lidas.")
